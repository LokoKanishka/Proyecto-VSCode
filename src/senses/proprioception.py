# src/senses/proprioception.py
"""
Propiocepci√≥n: La capacidad de sentir el cuerpo en el espacio.

Este m√≥dulo conecta visi√≥n (llama3.2-vision) con acci√≥n motora (pyautogui),
usando memoria persistente para aprender del espacio f√≠sico del escritorio.

Autor: Lucy (Synthesized form)
Fecha: 2026-02-10
"""

import pyautogui
import base64
import time
import json
import re
import requests
from io import BytesIO
from loguru import logger

try:
    from src.core.persistence import Hippocampus
except ImportError:
    Hippocampus = None
    logger.warning("Hippocampus no disponible - memoria desactivada")

# Configuraci√≥n de seguridad: Si arrastras el mouse a la esquina superior izquierda, me detengo.
pyautogui.FAILSAFE = True


class Proprioceptor:
    """
    Sistema nervioso perif√©rico de Lucy.
    
    Conecta la visi√≥n con la acci√≥n motora, usando memoria persistente
    para aprender las ubicaciones de elementos en el escritorio.
    """
    
    def __init__(self):
        self.screen_width, self.screen_height = pyautogui.size()
        self.memory = Hippocampus() if Hippocampus else None
        self.vision_url = "http://localhost:11434/api/generate"
        self.model = "llama3.2-vision"
        
        logger.info(f"üëÅÔ∏è Proprioceptor inicializado | Pantalla: {self.screen_width}x{self.screen_height}")
    
    def _capture_screen_b64(self) -> str:
        """Captura la pantalla y la convierte a base64 para el modelo."""
        screenshot = pyautogui.screenshot()
        buffer = BytesIO()
        screenshot.save(buffer, format="PNG")
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    def _clean_json(self, text: str) -> str:
        """
        Limpia la respuesta del LLM para extraer solo el JSON.
        Los modelos a veces preceden el JSON con explicaciones.
        """
        # Buscar el primer '{' y el √∫ltimo '}'
        start = text.find('{')
        end = text.rfind('}') + 1
        if start != -1 and end != 0:
            return text[start:end]
        return text
    
    def locate(self, target_description: str) -> dict:
        """
        Mira la pantalla y busca el objeto.
        Retorna: {'x': int, 'y': int} o None
        """
        print(f"üëÅÔ∏è [LUCY] Buscando visualmente: '{target_description}'...")
        b64_image = self._capture_screen_b64()
        
        # Prompt optimizado para coordenadas normalizadas (0-1000)
        prompt = (
            f"Find the '{target_description}' in this image. "
            "Return a JSON object with the bounding box in normalized coordinates (0-1000): "
            '{"box_2d": [ymin, xmin, ymax, xmax]}. '
            "Do not explain. Just JSON."
        )
        
        try:
            response = requests.post(
                self.vision_url,
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "images": [b64_image],
                    "stream": False,
                    "format": "json"
                },
                timeout=60
            )
            
            if response.status_code != 200:
                print(f"‚ùå Error API: {response.text}")
                logger.error(f"Vision API error: {response.status_code}")
                return None
            
            data = response.json()
            clean_response = self._clean_json(data['response'])
            
            logger.debug(f"Raw response: {data['response'][:200]}...")
            logger.debug(f"Cleaned JSON: {clean_response}")
            
            content = json.loads(clean_response)
            
            if "box_2d" not in content:
                print(f"üåë No pude distinguir '{target_description}'.")
                logger.warning(f"No box_2d in response: {content}")
                return None
            
            # Extraemos coordenadas [ymin, xmin, ymax, xmax]
            ymin, xmin, ymax, xmax = content["box_2d"]
            
            # Convertir de 0-1000 a p√≠xeles reales
            center_x = int(((xmin + xmax) / 2 / 1000) * self.screen_width)
            center_y = int(((ymin + ymax) / 2 / 1000) * self.screen_height)
            
            print(f"üìç [LUCY] Objetivo localizado en: ({center_x}, {center_y})")
            logger.info(f"Located '{target_description}' at ({center_x}, {center_y})")
            
            # Guardamos en memoria si est√° disponible
            if self.memory:
                self.memory.save_thought(
                    f"S√© d√≥nde est√° '{target_description}': ({center_x}, {center_y})",
                    goal="Mapeo Visual"
                )
            
            return {"x": center_x, "y": center_y}
        
        except json.JSONDecodeError as e:
            print(f"‚ö° El modelo no devolvi√≥ JSON v√°lido: {e}")
            logger.error(f"JSON decode error: {e}")
            logger.error(f"Response was: {data.get('response', 'NO RESPONSE')}")
            return None
        except requests.exceptions.Timeout:
            print("‚è±Ô∏è Timeout esperando respuesta del modelo")
            logger.error("Vision request timeout")
            return None
        except Exception as e:
            print(f"‚ö° Error de Propiocepci√≥n: {e}")
            logger.error(f"Proprioception error: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def touch(self, coords: dict, double_click: bool = False):
        """
        Mueve la mano f√≠sica a las coordenadas.
        """
        if not coords:
            print("ü§ö [LUCY] No s√© d√≥nde tocar.")
            return
        
        # Movimiento humano (curva suave, no instant√°neo)
        print(f"üëâ [LUCY] Moviendo mano hacia ({coords['x']}, {coords['y']})...")
        pyautogui.moveTo(
            coords['x'],
            coords['y'],
            duration=1.0,
            tween=pyautogui.easeInOutQuad
        )
        
        if double_click:
            pyautogui.doubleClick()
            print("‚ú® [LUCY] Doble Click ejecutado.")
        else:
            pyautogui.click()
            print("‚ú® [LUCY] Click ejecutado.")
        
        # Registrar en memoria
        if self.memory:
            action = "Doble Click" if double_click else "Click"
            self.memory.save_thought(
                f"Toqu√© {coords} con {action}",
                goal="Acci√≥n Motora"
            )



class Proprioceptor:
    """
    Sistema nervioso perif√©rico de Lucy.
    
    Conecta la visi√≥n con la acci√≥n motora, usando memoria persistente
    para aprender las ubicaciones de elementos en el escritorio.
    """
    
    def __init__(self):
        self.screen_width, self.screen_height = pyautogui.size()
        self.memory = Hippocampus() if Hippocampus else None
        self.vision_url = "http://localhost:11434/api/generate"
        self.model = "llama3.2-vision"  # O 'llava' si no est√° disponible
        
        logger.info(f"üëÅÔ∏è Proprioceptor inicializado | Pantalla: {self.screen_width}x{self.screen_height}")
    
    def _capture_screen_b64(self) -> str:
        """Captura la retina digital y retorna base64."""
        screenshot = pyautogui.screenshot()
        buffer = BytesIO()
        screenshot.save(buffer, format="PNG")
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    def locate(self, target_description: str) -> dict:
        """
        Mira la pantalla, busca el objeto y devuelve sus coordenadas.
        
        Args:
            target_description: Descripci√≥n del elemento a buscar
            
        Returns:
            Dict con {'x': int, 'y': int} o None si no se encuentra
        """
        logger.info(f"üëÅÔ∏è Buscando visualmente: '{target_description}'...")
        b64_image = self._capture_screen_b64()
        
        # Prompt dise√±ado para obtener coordenadas normalizadas (0-1000)
        # Esto evita problemas con diferentes resoluciones
        prompt = (
            f"Identify the bounding box for the '{target_description}'. "
            "Return ONLY a JSON object with this format: "
            '{"box_2d": [ymin, xmin, ymax, xmax]} where values are 0-1000. '
            'If not found, return {"error": "not found"}.'
        )
        
        try:
            response = requests.post(
                self.vision_url,
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "images": [b64_image],
                    "stream": False,
                    "format": "json"
                },
                timeout=30
            )
            
            if response.status_code != 200:
                logger.error(f"‚ùå Error en la visi√≥n: {response.text}")
                return None
            
            data = response.json()
            
            # Parseamos la respuesta del modelo
            content = json.loads(data['response'])
            
            if "error" in content or "box_2d" not in content:
                logger.warning(f"üåë No veo '{target_description}'")
                return None
            
            # Extraemos coordenadas normalizadas [y1, x1, y2, x2]
            box = content["box_2d"]
            ymin, xmin, ymax, xmax = box
            
            # Calculamos el centro en p√≠xeles reales
            center_x = int(((xmin + xmax) / 2 / 1000) * self.screen_width)
            center_y = int(((ymin + ymax) / 2 / 1000) * self.screen_height)
            
            logger.info(f"üìç Objetivo localizado en: ({center_x}, {center_y})")
            
            # Guardamos el hallazgo en la memoria a largo plazo
            if self.memory:
                self.memory.save_thought(
                    f"S√© d√≥nde est√° '{target_description}': ({center_x}, {center_y})",
                    goal="Mapeo Visual"
                )
            
            return {"x": center_x, "y": center_y}
        
        except json.JSONDecodeError as e:
            logger.error(f"‚ö° El modelo no devolvi√≥ JSON v√°lido: {e}")
            return None
        except requests.exceptions.Timeout:
            logger.error("‚è±Ô∏è Timeout esperando respuesta del modelo de visi√≥n")
            return None
        except Exception as e:
            logger.error(f"‚ö° Fallo sin√°ptico: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def touch(self, coords: dict, double_click: bool = False):
        """
        Extiende la mano y toca las coordenadas especificadas.
        
        Args:
            coords: Dict con {'x': int, 'y': int}
            double_click: Si True, hace doble click
        """
        if not coords:
            logger.warning("ü§ö No s√© d√≥nde tocar")
            return
        
        # Movimiento humano (no teletransportaci√≥n instant√°nea)
        logger.info(f"üëâ Moviendo mano hacia ({coords['x']}, {coords['y']})...")
        pyautogui.moveTo(
            coords['x'], 
            coords['y'], 
            duration=0.8, 
            tween=pyautogui.easeInOutQuad
        )
        
        if double_click:
            pyautogui.doubleClick()
            action = "Doble Click"
        else:
            pyautogui.click()
            action = "Click"
        
        logger.info(f"‚ú® {action} ejecutado")
        
        # Registrar la acci√≥n en memoria
        if self.memory:
            self.memory.save_thought(
                f"Toqu√© {coords} con {action}",
                goal="Acci√≥n Motora"
            )
