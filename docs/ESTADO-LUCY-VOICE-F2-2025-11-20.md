# ESTADO ‚Äì Lucy Voz (Fase 2) ‚Äì 20/11/2025

## Resumen r√°pido

En esta fecha, Lucy Voz tiene:

- **Modo voz push-to-talk estable**:
  - Comando: `python -m lucy_voice.voice_chat_loop`
  - Lucy escucha cuando apret√°s **Enter**, responde por voz y vuelve a esperar.
- **Salida limpia del LLM**:
  - Lucy ya no lee en voz partes tipo ‚ÄúThinking‚Ä¶‚Äù ni explicaciones internas.
  - Solo habla la frase final en castellano (‚Äús√≠, ¬øen qu√© te puedo ayudar?‚Äù, etc.).
- **Half-duplex pr√°ctico**:
  - Mientras habla, Lucy **no escucha**.
  - Cuando termina de hablar, vuelve a mostrar `[Enter=hablar | 'salir'=terminar]:`
  - Esto evita que se pisen tu voz y la de Lucy.

Todo corre 100% local sobre Ubuntu, usando Ollama + gpt-oss:20b, faster-whisper y Mimic3.

---

## Cambios hechos hoy

1. **Correcci√≥n de `voice_chat_loop.py`**
   - Se coment√≥ la llamada a `pipeline.build_graph()` porque el grafo de Pipecat todav√≠a es un stub y no es necesario para este modo.
   - Se agreg√≥ el import correcto:
     - `from lucy_voice.pipeline_lucy_voice import LucyVoicePipeline, LucyPipelineConfig`
   - Resultado:
     - `python -m lucy_voice.voice_chat_loop` ahora inicia sin errores.

2. **Prueba manual del modo voz por turnos**
   - Comandos usados:
     ```bash
     cd ~/Lucy_Workspace/Proyecto-VSCode
     source .venv-lucy-voz/bin/activate
     python -m lucy_voice.voice_chat_loop
     ```
   - Comportamiento observado:
     - Aparece:
       - `Lucy voz (modo VOZ).`
       - `Cada turno:`
       - `  - Apret√° Enter solo para grabar`
       - `  - Escrib√≠ 'salir' y Enter para terminar`
       - `[Enter=hablar | 'salir'=terminar]:`
     - Al apretar **Enter**:
       - Lucy graba unos segundos.
       - El usuario dice ‚Äú¬øme escuch√°s?‚Äù
       - Lucy responde en voz: ‚Äús√≠, ¬øen qu√© te puedo ayudar?‚Äù (u otra frase similar, clara).
       - Vuelve a mostrarse `[Enter=hablar | 'salir'=terminar]:`
     - Al escribir `salir` y Enter:
       - Muestra: `[LucyVoiceVoiceChat] Fin de la sesi√≥n de voz. Chau üíú`
       - Vuelve al prompt de Linux.

---

## Estado funcional actual (resumen para futuro)

- **Modo texto**:
  - `python -m lucy_voice.pipeline_lucy_voice`
  - Sirve para charlar con Lucy por consola, sin audio.

- **Modo voz ‚Äì una sola ronda**:
  - `./scripts/lucy_voice_mic_roundtrip.sh`
  - Escucha ‚Üí entiende ‚Üí responde por voz ‚Üí vuelve a la consola.

- **Modo voz ‚Äì conversaci√≥n por turnos (push-to-talk)**:
  - `python -m lucy_voice.voice_chat_loop`
  - Varios turnos:
    - Enter = hablar
    - Lucy responde en voz
    - `salir` = terminar sesi√≥n

Todo esto est√° usando:
- LLM local v√≠a Ollama (`gpt-oss:20b`)
- ASR local con `faster-whisper` (modelo `small`, CPU, espa√±ol)
- TTS local con Mimic3 (voz en castellano)

---

## Pr√≥ximos pasos previstos (seg√∫n hoja de ruta)

1. **Hotword / wake word (‚Äúhola Lucy‚Äù)**
   - Implementar un modo en el que Lucy est√© ‚Äúapagada pero escuchando bajito‚Äù.
   - Cuando detecta la frase ‚Äúhola Lucy‚Äù, dispare _un turno_ completo equivalente a `voice_chat_loop` (escuchar ‚Üí entender ‚Üí responder en voz).

2. **Integraci√≥n m√°s profunda con Pipecat**
   - Migrar el flujo actual de:
     - micr√≥fono ‚Üí ASR ‚Üí LLM ‚Üí TTS
   - a un grafo real de Pipecat con nodos de audio y estados claros (escuchando / pensando / hablando).

3. **Tool calling + LucyTools**
   - Permitir que Lucy, adem√°s de hablar, pueda ejecutar acciones de escritorio (abrir aplicaciones, capturas, etc.) de forma segura, usando JSON de herramientas y el m√≥dulo `lucy_tools.py`.

