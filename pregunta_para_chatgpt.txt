Hola, necesito ayuda técnica experta con un sistema de Wake Word personalizado usando `openwakeword` y `pipecat`.

**Contexto:**
Estoy desarrollando un asistente de voz local ("Lucy").
- Framework: Pipecat.
- Wake Word Engine: `openwakeword`.
- Modelo personalizado: Entrenado con `sklearn.LogisticRegression` y exportado a ONNX.

**El Problema:**
El modelo personalizado ("Hola Lucy") genera falsos positivos infinitos o detecciones constantes, incluso con silencio.
Originalmente, el modelo ONNX exportado por `skl2onnx` esperaba una entrada 2D `(batch, features)`, pero `openwakeword` le envía una entrada 3D `(batch, time, features)` (ej: `1, 16, 96`).
Esto causaba un error de "Invalid Rank".

**Lo que intentamos:**
1. Modificamos el script de entrenamiento (`train.py`) para "parchear" el grafo ONNX insertando un nodo `Flatten` al principio.
2. Esto solucionó el crash, pero ahora el modelo parece predecir la clase positiva ("1") constantemente o con scores muy altos, resultando en un bucle de detecciones.
3. En `wakeword_node.py`, mapeamos la salida "1" a "hola_lucy" y "0" a ignorar, pero el comportamiento persiste.

**Archivos adjuntos:**
En el archivo `codigo_fuente.txt` encontrarás:
1. `wakeword_node.py`: Lógica de inferencia.
2. `audio_node.py`: Captura de audio.
3. `train.py`: Script de entrenamiento y parcheo ONNX.
4. `config.yaml`: Configuración.

**Pregunta:**
¿Qué está mal en mi estrategia de entrenamiento o en el parcheo del modelo ONNX? ¿Cómo debo entrenar correctamente un modelo personalizado para `openwakeword` (versión reciente) usando mis propios embeddings extraídos, de manera que acepte la entrada 3D que `openwakeword` envía por defecto y prediga correctamente sin falsos positivos constantes?
