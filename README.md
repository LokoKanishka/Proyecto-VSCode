# Lucy Voice - Asistente de Voz Local (Nodo Modular)

> Ãšltima actualizaciÃ³n automÃ¡tica: 2025-12-01 23:20:58 -03

Lucy es un asistente de voz **100% local y open source** pensado para correr en una PC de escritorio con Linux (Ubuntu), usando:

- Reconocimiento de voz (ASR) local
- LLM local vÃ­a **Ollama**
- TTS local con **Mimic3**
- Control de aplicaciones y herramientas del sistema

Desde fines de 2025 el **modo oficial** de Lucy Voz es el **nodo de voz modular**, y el pipeline anterior con wake word / Pipecat pasÃ³ a ser **LEGACY**.

---

## 1. Arquitectura actual (Lucy Voz v2)

La arquitectura actual se organiza asÃ­:

- **Repositorio principal:** `Proyecto-VSCode`
- **Nodo de voz modular:** submÃ³dulo en  
  `external/nodo-de-voz-modular-de-lucy`
- **Lanzador oficial de voz:**  
  `scripts/lucy_voice_modular_node.sh`
- **Acceso directo grÃ¡fico:**  
  `lucy.desktop` â†’ apunta al lanzador anterior

El nodo modular integra:

- **ASR:** Whisper (vÃ­a `openai-whisper`)
- **LLM:** Ollama (p. ej. `gpt-oss:20b`)
- **TTS:** Mimic3 (`es_ES/m-ailabs_low` u otra voz)
- **VAD:** `webrtcvad` para modo manos libres
- **Comando de sueÃ±o:** "lucy dormi" / "lucy dormÃ­" para terminar la sesiÃ³n por voz

El pipeline Pipecat + wakeword ONNX vive ahora en `legacy/` y solo se conserva como referencia histÃ³rica.

ğŸ“¦ Para detalles sobre mÃ³dulos legacy, backups y cÃ³digo experimental que no forma parte de Lucy Voz v2, ver `docs/LUCY-MODULOS-LEGACY.md`.

---

## 2. CaracterÃ­sticas principales (modo modular)

- âœ… **Modo manos libres** con VAD  
  PresionÃ¡s **Enter una sola vez** y Lucy entra en un bucle:
  escucha â†’ transcribe â†’ piensa â†’ habla â†’ vuelve a escuchar.

- âœ… **Comando de sueÃ±o por voz**  
  Si la transcripciÃ³n contiene el comando de cierre (por ej. _"lucy dormi"_), Lucy:
  - confirma que recibiÃ³ la orden
  - cierra la sesiÃ³n de forma limpia

- âœ… **100% local / offline**  
  - Whisper local
  - Ollama local
  - Mimic3 local

- âœ… **ParÃ¡metros visibles**  
  En cada arranque se muestran (en la terminal):
  - voz Mimic3
  - `Emotion exaggeration`
  - `CFG weight`
  - modelo LLM actual (`gpt-oss:20b`, etc.)

---

## 3. Requisitos

- Linux (probado en Ubuntu)
- Python 3.12+
- Ollama instalado y corriendo (con el modelo que quieras usar, por ejemplo `gpt-oss:20b`)
- Mimic3 instalado
- MicrÃ³fono y salida de audio configurados

---

## 4. InstalaciÃ³n

Clonar el repo:

```bash
git clone https://github.com/LokoKanishka/Proyecto-VSCode.git
cd Proyecto-VSCode
````

Crear entorno virtual e instalar dependencias:

```bash
./scripts/install_deps.sh
```

(El script crea `.venv-lucy-voz` y resuelve las dependencias de Lucy Voz y del nodo modular.)

---

## 5. Uso rÃ¡pido

### 5.1. Desde el acceso directo grÃ¡fico

1. InstalÃ¡ el `.desktop` (si aÃºn no lo hiciste):

   * Copiar `lucy.desktop` a:

     * `~/.local/share/applications/`
     * (opcional) `/usr/share/applications/` para que sea global

2. BuscÃ¡ **"Lucy"** en el menÃº de aplicaciones y hacÃ© clic.

3. Se abre una terminal con algo del estilo:

   ```text
   ğŸ¤– Local Voice Assistant with Mimic3 TTS
   Using Mimic3 voice: es_ES/m-ailabs_low
   Emotion exaggeration: 0.5
   CFG weight: 0.5
   LLM model: gpt-oss:20b

   Press Enter once to start speaking (Ctrl+C to exit).
   ```

4. PresionÃ¡ **Enter una vez** para empezar el bucle de escucha.

### 5.2. Desde consola

```bash
cd ~/Lucy_Workspace/Proyecto-VSCode
./scripts/lucy_voice_modular_node.sh
```

El flujo es el mismo que con el acceso directo.

---

## 6. ConfiguraciÃ³n

La configuraciÃ³n general vive en `config.yaml` en la raÃ­z del proyecto.

Ejemplo mÃ­nimo de parÃ¡metros relevantes:

```yaml
ollama_model: "gpt-oss:20b"
sample_rate: 16000

voice_modular:
  enabled: true
  whisper_model: "base"
  vad_sample_rate: 16000
  vad_aggressiveness: 2
  sleep_commands:
    - "lucy dormi"
    - "lucy dormÃ­"
```

> âš ï¸ El resto de claves de `config.yaml` puede variar; revisÃ¡ el archivo real en tu repo local.

DocumentaciÃ³n ampliada del nodo modular: ver `docs/VOICE_MODULAR.md`.

---

## 7. Estructura del proyecto (resumen)

```text
Proyecto-VSCode/
â”œâ”€â”€ external/
â”‚   â””â”€â”€ nodo-de-voz-modular-de-lucy/   # Nodo de voz modular (ASR + VAD + TTS + LLM)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ lucy_voice_modular_node.sh     # Lanzador oficial (v2)
â”‚   â”œâ”€â”€ cleanup_old_voice_system.sh    # Script de limpieza del pipeline viejo
â”‚   â””â”€â”€ ...                            # Otros scripts varios
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ VOICE_MODULAR.md               # DocumentaciÃ³n del nodo modular
â”‚   â”œâ”€â”€ LEGACY_VOICE_PIPELINE.md       # DescripciÃ³n del pipeline Pipecat legado
â”‚   â””â”€â”€ backup/                        # Backups automÃ¡ticos de README/config
â”œâ”€â”€ lucy_web/                          # CÃ³digo web / tools auxiliares
â”œâ”€â”€ legacy/                            # Sistema de voz viejo (wakeword + Pipecat)
â”œâ”€â”€ config.yaml
â”œâ”€â”€ lucy.desktop
â””â”€â”€ ...
```

---

## 8. Pipeline viejo (LEGACY)

El sistema original de Lucy Voz estaba basado en:

* Pipeline de audio/conversaciÃ³n con **Pipecat**
* Wake word entrenada con **OpenWakeWord** (ej. "Hola Lucy")
* ASR con **Faster Whisper**
* Scripts de entrenamiento y prueba de wake word
* Varios scripts `fix_*` para preparar/limpiar el entorno

Todo ese cÃ³digo se moviÃ³ a `legacy/` para que no interfiera con el flujo actual, pero se conserva como:

* referencia tÃ©cnica,
* y posible base para experimentos futuros.

Para mÃ¡s detalle histÃ³rico, ver `docs/LEGACY_VOICE_PIPELINE.md`.
